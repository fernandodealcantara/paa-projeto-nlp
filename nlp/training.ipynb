{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -U pip setuptools wheel\n",
    "!pip3 install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ner.pythonhumanities.com/03_01_create_ner_training_set.html\n",
    "# https://ner.pythonhumanities.com/03_02_train_spacy_ner_model.html\n",
    "import json\n",
    "import spacy\n",
    "import json\n",
    "import warnings\n",
    "import random\n",
    "from spacy.tokens import DocBin\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import utils # local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregar características\n",
    "caracteristicas = utils.carregar_json(\"../data/caracteristicas.json\")\n",
    "# corrigir caracteristicas duplicadas\n",
    "caracteristicas = list(set(caracteristicas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pessoas = utils.carregar_json(\"../data/dados_pessoas.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_pt = spacy.load(\"pt_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1756/1756 [02:42<00:00, 10.80it/s]\n"
     ]
    }
   ],
   "source": [
    "docs = [nlp_pt(p[\"biografia\"]) for p in tqdm(pessoas)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentencas = [s.text for doc in docs for s in doc.sents] # lista de sentenças de todas as biografias\n",
    "todas_sentencas = [s.text for doc in docs for s in doc.sents]\n",
    "boas_sentencas = [\n",
    "    s\n",
    "    for s in todas_sentencas\n",
    "    if any(c in s for c in [\"foi\", \"é uma\", \"é um\", \"atuou\", \"atua\", \"era\"])\n",
    "]\n",
    "melhores_sentencas = [next(doc.sents).text for doc in docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "crcs_para_treinar = caracteristicas.copy()  # nenhuma característica foi treinada ainda\n",
    "sentencas_para_treinar = []\n",
    "# adicionar sentenças que contenham características\n",
    "for sentenca in boas_sentencas:\n",
    "    # verificar se a sentença contém características\n",
    "    crcs_na_stc = [c for c in crcs_para_treinar if c in sentenca]\n",
    "\n",
    "    if len(crcs_na_stc) > 0:  # se a sentença contém características\n",
    "        sentencas_para_treinar.append(sentenca)  # adicionar a sentença\n",
    "        # remover as características da lista de características para treinar\n",
    "        crcs_para_treinar = [c for c in crcs_para_treinar if c not in crcs_na_stc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(554, 1493)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentencas_para_validar = melhores_sentencas.copy()\n",
    "\n",
    "# remover sentenças para validar do conjunto que estão sendo usadas para treinar\n",
    "sentencas_para_validar = [s for s in sentencas_para_validar if s not in sentencas_para_treinar]\n",
    "\n",
    "len(sentencas_para_treinar), len(sentencas_para_validar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\n",
    "    {\"label\": \"CARACTERISTICA\", \"pattern\": caracteristica}\n",
    "    for caracteristica in caracteristicas\n",
    "]\n",
    "\n",
    "lista_treino = sentencas_para_treinar + random.sample(sentencas_para_validar[:400], 300)\n",
    "lista_validacao = random.sample(sentencas_para_validar, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 854/854 [00:01<00:00, 583.24it/s]\n",
      "100%|██████████| 400/400 [00:00<00:00, 621.34it/s]\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA = utils.formatar(lista_treino, patterns)\n",
    "VALID_DATA = utils.formatar(lista_validacao, patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.salvar_json(\"../data/train_data.json\", TRAIN_DATA)\n",
    "utils.salvar_json(\"../data/valid_data.json\", VALID_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 854/854 [00:01<00:00, 552.32it/s]\n",
      "100%|██████████| 400/400 [00:00<00:00, 630.78it/s]\n"
     ]
    }
   ],
   "source": [
    "utils.converter(\"pt\", TRAIN_DATA, \"../data/train.spacy\")\n",
    "utils.converter(\"pt\", VALID_DATA, \"../data/valid.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: ../data/models\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-02-04 02:12:38,729] [INFO] Set up nlp object from config\n",
      "[2023-02-04 02:12:38,795] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2023-02-04 02:12:38,814] [INFO] Created vocabulary\n",
      "[2023-02-04 02:12:38,818] [INFO] Finished initializing nlp object\n",
      "[2023-02-04 02:12:41,173] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     13.67    0.00    0.00    0.00    0.00\n",
      "  0     200         49.32   1554.85   96.19   94.55   97.89    0.96\n",
      "  2     400         48.02    337.65   98.01   97.18   98.85    0.98\n",
      "  3     600         73.69    106.92   98.30   97.28   99.33    0.98\n",
      "  5     800         43.44     55.34   98.25   97.28   99.23    0.98\n",
      "  7    1000         60.94     45.21   98.30   97.28   99.33    0.98\n",
      " 10    1200         37.11     26.93   98.16   97.01   99.33    0.98\n",
      " 13    1400         63.36     33.98   98.44   97.47   99.43    0.98\n",
      " 17    1600         38.96     21.32   97.83   96.38   99.33    0.98\n",
      " 23    1800         46.77     21.73   98.06   96.83   99.33    0.98\n",
      " 29    2000         53.42     23.90   97.92   96.56   99.33    0.98\n",
      " 37    2200         49.20     18.17   98.48   97.56   99.43    0.98\n",
      " 46    2400         50.41     19.74   98.57   98.01   99.14    0.99\n",
      " 55    2600         94.90     25.69   97.88   96.38   99.43    0.98\n",
      " 65    2800         58.02     27.15   98.06   96.83   99.33    0.98\n",
      " 75    3000         32.06     13.31   98.06   96.83   99.33    0.98\n",
      " 84    3200         21.29      9.42   98.30   97.19   99.43    0.98\n",
      " 94    3400          5.20      2.51   98.02   96.65   99.43    0.98\n",
      "103    3600         10.01      1.99   97.97   96.56   99.43    0.98\n",
      "113    3800          0.00      0.00   98.11   96.83   99.43    0.98\n",
      "122    4000         36.42      8.69   97.51   95.67   99.43    0.98\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "../data/models/model-last\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy train config.cfg --output ../data/models --paths.train ../data/train.spacy --paths.dev ../data/valid.spacy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
